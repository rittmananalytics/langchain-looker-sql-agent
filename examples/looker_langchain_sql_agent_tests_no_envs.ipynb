{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5eb482-58e3-477b-ae96-bdb8228f2346",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get update\n",
    "!sudo apt-get install -y openjdk-11-jdk --no-install-recommends\n",
    "!java -version # Verify installation\n",
    "!export JAVA_HOME=$(java -XshowSettings:properties -version 2>&1 > /dev/null | grep 'java.home' | awk '{print $3}')\n",
    "!echo $JAVA_HOME\n",
    "!mkdir drivers\n",
    "!cd drivers\n",
    "!wget https://github.com/looker-open-source/calcite-avatica/releases/download/avatica-1.26.0-looker/avatica-1.26.0-looker.jar\n",
    "!pip install langchain-looker-agent langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac092c0-2a40-4c5b-a000-fe3b9579f71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "# It's good practice for examples to configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from langchain_looker_agent import LookerSQLDatabase, LookerSQLToolkit, create_looker_sql_agent\n",
    "from langchain_openai import ChatOpenAI # Example LLM\n",
    "from langchain.memory import ConversationBufferMemory # For conversational agent\n",
    "from langchain.agents import AgentExecutor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1943a38-237a-4a79-8423-9bb4dedcb8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "JDBC_FULL_DRIVER_PATH = \"/home/jupyter/drivers/avatica-1.26.0-looker.jar\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\" ## OPEN AI API KEY\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "LOOKER_INSTANCE_URL = \"\" ## e.g. \"https://rittman.eu.looker.com\"\n",
    "LOOKML_MODEL_NAME = \"\" ## e.g. \"analytics\"\n",
    "CLIENT_ID = \"\" ## API 3.0 CLIENT ID\n",
    "CLIENT_SECRET = \"\"  ## API 3.0 CLIENT_SECRET\n",
    "\n",
    "db = LookerSQLDatabase(\n",
    "    looker_instance_url=LOOKER_INSTANCE_URL,\n",
    "    lookml_model_name=LOOKML_MODEL_NAME,\n",
    "    client_id=CLIENT_ID,\n",
    "    client_secret=CLIENT_SECRET,\n",
    "    jdbc_driver_path=JDBC_FULL_DRIVER_PATH,\n",
    "    sample_rows_in_table_info=0 # Disable samples for quickstart simplicity\n",
    "    )\n",
    "\n",
    "logger.info(\"LookerSQLDatabase initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feac434-a617-47c8-8292-987bc5e3b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = None\n",
    "memory = None\n",
    "looker_toolkit = None\n",
    "\n",
    "if db and db._connection: \n",
    "    try:\n",
    "        logger.info(\"Initializing LLM...\")\n",
    "        llm = ChatOpenAI(model=\"gpt-4o\", temperature=0) \n",
    "        logger.info(f\"LLM initialized: {llm.model_name}\")\n",
    "\n",
    "        logger.info(\"Initializing ConversationBufferMemory...\")\n",
    "        memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "        logger.info(\"ConversationBufferMemory initialized.\")\n",
    "\n",
    "        logger.info(\"Initializing LookerSQLToolkit...\")\n",
    "        looker_toolkit = LookerSQLToolkit(db=db)\n",
    "        logger.info(\"LookerSQLToolkit initialized.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error initializing LLM, Memory, or Toolkit: {e}\", exc_info=True)\n",
    "else:\n",
    "    logger.warning(\"Skipping LLM, Memory, and Toolkit initialization as database connection failed.\")\n",
    "\n",
    "agent_executor = None\n",
    "if llm and looker_toolkit and memory:\n",
    "    try:\n",
    "        logger.info(\"Creating the Looker SQL Agent Executor...\")\n",
    "        agent_executor = create_looker_sql_agent(\n",
    "            llm=llm,\n",
    "            toolkit=looker_toolkit,\n",
    "            verbose=True, \n",
    "            top_k=10, \n",
    "            agent_executor_kwargs={\n",
    "                \"memory\": memory,\n",
    "                \"handle_parsing_errors\": True, \n",
    "                \"max_iterations\": 10 # Increased for potentially complex reasoning\n",
    "            }\n",
    "        )\n",
    "        logger.info(\"Looker SQL Agent Executor created successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to create Looker SQL Agent Executor: {e}\", exc_info=True)\n",
    "else:\n",
    "    logger.warning(\"Skipping Agent Executor creation due to missing LLM, Toolkit, or Memory.\")\n",
    "\n",
    "def run_agent_test_case(question: str, agent_exec: AgentExecutor, test_name: str):\n",
    "    \"\"\"Helper function to run a single test case for the agent.\"\"\"\n",
    "    if not agent_exec:\n",
    "        logger.warning(f\"AGENT TEST SKIPPED ({test_name}): Agent Executor not initialized.\")\n",
    "        print(f\"\\n--- SKIPPING TEST: {test_name} (Agent not initialized) ---\")\n",
    "        print(f\"QUESTION: {question}\")\n",
    "        return \"Agent not initialized.\"\n",
    "        \n",
    "    logger.info(f\"\\n--- Running Agent Test: {test_name} ---\")\n",
    "    print(f\"\\n--- Running Agent Test: {test_name} ---\")\n",
    "    print(f\"QUESTION: {question}\")\n",
    "    \n",
    "    # Persona/task instruction for the agent for this specific query\n",
    "    # Note: The main SQL syntax rules are already in the agent's system prompt.\n",
    "    instruction_prefix = f\"\"\"You are a helpful data analyst for Rittman Analytics, querying data through Looker.\n",
    "The user is asking about data available in our Looker instance via the model '{LOOKML_MODEL_NAME}'.\n",
    "If the question involves a calculation on a LookML measure (often indicated by `MEASURE<TYPE>` in the schema), \n",
    "ensure you wrap that measure with `AGGREGATE()`. For example, `SELECT AGGREGATE(\\`view.measure_field\\`) ...`.\n",
    "Question: \"\"\"\n",
    "    \n",
    "    full_question_for_agent = instruction_prefix + question\n",
    "\n",
    "    try:\n",
    "        # AgentExecutor with memory handles chat_history implicitly if memory was passed during its creation.\n",
    "        # For isolated tests, we still pass an empty chat_history to ensure the prompt is satisfied.\n",
    "        response = agent_exec.invoke({\n",
    "            \"input\": full_question_for_agent,\n",
    "            \"chat_history\": [] # Provide for stateless test invocation\n",
    "        }) \n",
    "        output = response.get(\"output\", \"No 'output' field in agent response.\")\n",
    "        print(f\"\\nAGENT RESPONSE for '{test_name}':\\n{output}\")\n",
    "        logger.info(f\"Agent response for '{test_name}': {output[:500]}{'...' if len(output) > 500 else ''}\")\n",
    "        return output\n",
    "    except Exception as e:\n",
    "        logger.error(f\"ERROR invoking agent for test '{test_name}' (Question: '{question}'): {e}\", exc_info=True)\n",
    "        print(f\"ERROR during agent invocation for '{test_name}': {e}\")\n",
    "        return f\"Error: {e}\"\n",
    "    finally:\n",
    "        print(\"-\" * 70)\n",
    "\n",
    "# %%\n",
    "if agent_executor:\n",
    "    logger.info(\"\\n--- Executing Pre-determined Agent Tests ---\")\n",
    "\n",
    "    # --- Test Case 1: List available Explores ---\n",
    "    run_agent_test_case(\n",
    "        question=\"List all available tables I can query.\",\n",
    "        agent_exec=agent_executor,\n",
    "        test_name=\"List Explores\"\n",
    "    )\n",
    "\n",
    "    # --- Determine an Explore to use for subsequent tests ---\n",
    "    explore_for_subsequent_tests = None\n",
    "    if db and db._connection:\n",
    "        try:\n",
    "            available_explores = list(db.get_usable_table_names())\n",
    "            if available_explores:\n",
    "                # Prefer 'web_sessions_fact' or 'chart_of_accounts_dim' if available, else first one\n",
    "                if \"web_sessions_fact\" in available_explores:\n",
    "                    explore_for_subsequent_tests = \"web_sessions_fact\"\n",
    "                elif \"chart_of_accounts_dim\" in available_explores:\n",
    "                    explore_for_subsequent_tests = \"chart_of_accounts_dim\"\n",
    "                else:\n",
    "                    explore_for_subsequent_tests = available_explores[0]\n",
    "                logger.info(f\"Will use Explore '{explore_for_subsequent_tests}' for subsequent targeted tests.\")\n",
    "            else:\n",
    "                logger.warning(\"No usable Explores found by db object; some tests might be skipped or use placeholders.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Could not dynamically get Explore names for tests: {e}\")\n",
    "    \n",
    "    if not explore_for_subsequent_tests:\n",
    "        logger.warning(\"explore_for_subsequent_tests is not set. Subsequent tests might fail if they rely on it.\")\n",
    "        explore_for_subsequent_tests = \"your_placeholder_explore\" # Fallback to a placeholder\n",
    "\n",
    "    # --- Test Case 2: Describe a specific Explore ---\n",
    "    run_agent_test_case(\n",
    "        question=f\"Describe the table named '{explore_for_subsequent_tests}'. What are its columns and provide a few sample rows if possible?\",\n",
    "        agent_exec=agent_executor,\n",
    "        test_name=f\"Describe Explore '{explore_for_subsequent_tests}'\"\n",
    "    )\n",
    "\n",
    "    # --- Test Case 3: Simple COUNT query ---\n",
    "    run_agent_test_case(\n",
    "        question=f\"How many records are in the '{explore_for_subsequent_tests}' table?\",\n",
    "        agent_exec=agent_executor,\n",
    "        test_name=f\"Count Records in '{explore_for_subsequent_tests}'\"\n",
    "    )\n",
    "\n",
    "    # --- Advanced Tests: Adapt these field names to YOUR Looker model ---\n",
    "    # Find these in the schema output from Test Case 2 or Looker UI.\n",
    "    # These are examples based on your previous logs for 'web_sessions_fact'\n",
    "    # If explore_for_subsequent_tests is different, these MUST be updated.\n",
    "    \n",
    "    measure_field_for_test = \"`web_events_fact.total_page_views`\" # Example, ensure this is a valid measure in explore_for_subsequent_tests\n",
    "    dimension_field_for_test = \"`web_sessions_fact.device_category`\" # Example dimension\n",
    "    dimension_value_for_test = \"desktop\" # Example value for the dimension\n",
    "\n",
    "    if explore_for_subsequent_tests == \"chart_of_accounts_dim\": # Example of adapting if explore changes\n",
    "        measure_field_for_test = \"`general_ledger_fact.net_amount`\" # Assuming this is a measure in chart_of_accounts_dim\n",
    "        dimension_field_for_test = \"`chart_of_accounts_dim.account_class`\"\n",
    "        dimension_value_for_test = \"ASSET\" # A plausible value\n",
    "        logger.info(f\"Adapting advanced test fields for explore: {explore_for_subsequent_tests}\")\n",
    "\n",
    "\n",
    "    # --- Test Case 4: Query a LookML Measure using AGGREGATE() ---\n",
    "    run_agent_test_case(\n",
    "        question=f\"What is the total of measure {measure_field_for_test} from the {explore_for_subsequent_tests} Explore?\",\n",
    "        agent_exec=agent_executor,\n",
    "        test_name=f\"Aggregate Measure {measure_field_for_test}\"\n",
    "    )\n",
    "\n",
    "    # --- Test Case 5: Measure aggregated by a dimension ---\n",
    "    run_agent_test_case(\n",
    "        question=f\"Show me the total {measure_field_for_test} grouped by {dimension_field_for_test} from the {explore_for_subsequent_tests} Explore.\",\n",
    "        agent_exec=agent_executor,\n",
    "        test_name=f\"Aggregate Measure by Dimension\"\n",
    "    )\n",
    "    \n",
    "    # --- Test Case 6: Measure with a WHERE clause on a dimension ---\n",
    "    run_agent_test_case(\n",
    "        question=f\"What is the total {measure_field_for_test} for {dimension_field_for_test} = '{dimension_value_for_test}' from the {explore_for_subsequent_tests} Explore?\",\n",
    "        agent_exec=agent_executor,\n",
    "        test_name=f\"Aggregate Measure with Filter\"\n",
    "    )\n",
    "\n",
    "    # --- Test Case 7: Query that should NOT use JOIN, subquery, or window function ---\n",
    "    run_agent_test_case(\n",
    "        question=f\"List the top 3 {dimension_field_for_test} by total {measure_field_for_test} from {explore_for_subsequent_tests}, ordered descending by that total.\",\n",
    "        agent_exec=agent_executor,\n",
    "        test_name=\"Top N without Window Functions\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    logger.error(\"Agent Executor not initialized. Cannot run pre-determined agent tests.\")\n",
    "    print(\"ERROR: Agent Executor could not be initialized. Please review setup cells for errors.\")\n",
    "\n",
    "\n",
    "# ## Phase 7: Cleanup (Optional) \n",
    "\n",
    "# %%\n",
    "if db:\n",
    "    try:\n",
    "        logger.info(\"Attempting to close Looker database connection...\")\n",
    "        db.close()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error closing Looker connection: {e}\", exc_info=True)\n",
    "else:\n",
    "    logger.info(\"No database connection (db object) to close or it was not initialized.\")\n",
    "\n",
    "logger.info(\"--- End of Looker SQL Agent Comprehensive Tests Notebook ---\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
